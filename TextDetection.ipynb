{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from imutils.perspective import four_point_transform\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# read, resize, and make a copy of the image\n",
    "img = cv2.imread('adobe.jpeg')\n",
    "img = cv2.resize(img, (600, 800))\n",
    "orig_img = img.copy()\n",
    "plt.imshow(orig_img)\n",
    "plt.show()\n",
    "\n",
    "# preprocess the image\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "edged = cv2.Canny(img, 100, 200)\n",
    "plt.imshow(edged,cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "dilated = cv2.dilate(edged,np.ones((5,5)), iterations=2)\n",
    "plt.imshow(dilated)\n",
    "plt.show()\n",
    "eroded = cv2.erode(dilated,np.ones((5,5)), iterations=1)\n",
    "plt.imshow(eroded)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# find and sort the contours\n",
    "contours, _ = cv2.findContours(eroded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "    \n",
    "# go through each contour\n",
    "chosen_contour = None\n",
    "for contour in contours:\n",
    "    # approximate each contour\n",
    "    peri = cv2.arcLength(contour, True)\n",
    "    approx = cv2.approxPolyDP(contour, 0.05 * peri, True)\n",
    "    # check if we have found our document\n",
    "    if len(approx) == 4:\n",
    "        doc_cnts = approx\n",
    "        break\n",
    "\n",
    "temp = orig_img.copy()\n",
    "temp1 = orig_img.copy()\n",
    "point_count = 0\n",
    "points = []\n",
    "\n",
    "window_name = 'Document Region'\n",
    "def Mouse_Event(event, x, y, flags, param):\n",
    "    global point_count\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        point_count += 1\n",
    "        # read colours at left clicked point\n",
    "        points.append([x,y])\n",
    "        cv2.circle(temp,(x,y),2,(0,0,255),2)\n",
    "        cv2.imshow(window_name,temp)\n",
    "\n",
    "        \n",
    "# cv2.drawContours(temp,[doc_cnts],-1,(0,255,0),3)\n",
    "# cv2.imshow(window_name, temp)\n",
    "# cv2.setMouseCallback(window_name, Mouse_Event)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyWindow(window_name)\n",
    "\n",
    "print(point_count)\n",
    "if point_count == 4:\n",
    "#     cv2.imshow('Modified Document Region',)\n",
    "    points = np.reshape(np.array(points),(4,1,2))\n",
    "    doc_cnts = points\n",
    "\n",
    "# apply warp perspective to get the top-down view\n",
    "warped = four_point_transform(orig_img, doc_cnts.reshape(4, 2))\n",
    "warped = cv2.cvtColor(warped, cv2.COLOR_BGR2GRAY)\n",
    "final_img = cv2.resize(warped, (600, 800))\n",
    "\n",
    "# write the image in the ouput directory\n",
    "cv2.imwrite(\"scannedPage.jpeg\", final_img)\n",
    "plt.imshow(final_img,cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "# blur = cv2.GaussianBlur(warped,(5,5),0)\n",
    "# ret3,th3 = cv2.threshold(warped,0,255,cv2.THRESH_OTSU)\n",
    "# plt.imshow(th3,cmap='gray')\n",
    "# plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# !sudo apt install tesseract-ocr\n",
    "# !pip install pytesseract\n",
    "from sortedcontainers import SortedDict\n",
    "from fpdf import FPDF\n",
    "import cv2\n",
    "import pytesseract"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DSj4RcPdtoul",
    "outputId": "eb781bcc-0c15-481b-995a-e61e2b703b9b"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "def getAlpha(s):\n",
    "    result = ''\n",
    "    for c in s:\n",
    "        if c >= 'a' and c <= 'z':\n",
    "            result += c\n",
    "        if c >= 'A' and c <= 'Z':\n",
    "            result += c\n",
    "        if c==' ':\n",
    "            result += c\n",
    "    return result.strip()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "img = cv2.imread(\"scannedPage.jpeg\")\n",
    "\n",
    "# Preprocessing the image starts\n",
    " \n",
    "# Convert the image to gray scale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    " \n",
    "# Performing OTSU threshold\n",
    "ret, thresh1 = cv2.threshold(gray, 0, 255, cv2.THRESH_OTSU | cv2.THRESH_BINARY_INV)\n",
    " \n",
    "# Specify structure shape and kernel size.\n",
    "# Kernel size increases or decreases the area\n",
    "# of the rectangle to be detected.\n",
    "# A smaller value like (10, 10) will detect\n",
    "# each word instead of a sentence.\n",
    "rect_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (15, 15))\n",
    " \n",
    "# Applying dilation on the threshold image\n",
    "dilation = cv2.dilate(thresh1, rect_kernel, iterations = 1)\n",
    " \n",
    "# Finding contours\n",
    "contours, hierarchy = cv2.findContours(dilation, cv2.RETR_EXTERNAL,\n",
    "                                                 cv2.CHAIN_APPROX_NONE)\n",
    " \n",
    "# Creating a copy of image\n",
    "im2 = img.copy()\n",
    " \n",
    "# A text file is created and flushed\n",
    "# file = open(\"recognized.txt\", \"w+\")\n",
    "# file.write(\"\")\n",
    "# file.close()\n",
    " \n",
    "# Looping through the identified contours\n",
    "# Then rectangular part is cropped and passed on\n",
    "# to pytesseract for extracting text from it\n",
    "# Extracted text is then written into the text file\n",
    "position_map = {}\n",
    "count = 0\n",
    "for i,cnt in enumerate(contours):\n",
    "    count += 1\n",
    "    x, y, w, h = cv2.boundingRect(cnt)\n",
    "     \n",
    "    # Drawing a rectangle on copied image\n",
    "    rect = cv2.rectangle(im2, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "     \n",
    "    # Cropping the text block for giving input to OCR\n",
    "    cropped = im2[y:y + h, x:x + w]\n",
    "     \n",
    "    # Open the file in append mode\n",
    "     \n",
    "    # Apply OCR on the cropped image\n",
    "    text = pytesseract.image_to_string(cropped)\n",
    "    text = getAlpha(text)\n",
    "    if text != '':\n",
    "        position_map[1000*y + x] = text\n",
    "    # if len(text) > 1:\n",
    "    #     file = open(\"recognized.txt\", \"a\")\n",
    "    #     # Appending the text into file\n",
    "    #     file.write(text)\n",
    "    #     file.write(\"\\n\")\n",
    "        \n",
    "    #     # Close the file\n",
    "    #     file.close()\n",
    "# print(count)\n",
    "d = SortedDict(position_map)\n",
    "for key in d.keys():\n",
    "    print(d[key])\n",
    "    print('-------------------------------------------')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Library of Souls                              TIE MONSTER STOOD toi tungues length away cyes fxcd on aSsoats sirled bran crowded with fantasies of murder Its hunger fortanith at Hollows are bom lusting uflr the souls of peculiars ated hereezvarapel before ke buf bitesized Addinon bravely standing hs Go tila attention mma moored against me for support al toxRete iepocl to make more than a match flame our hacks adder gaintsci phos boathHeyoud oar grim ci the undergruund stalion ledkedYeofimanath ua nighicub bombingSea irom burs pipes shricked forth in ghostly curtains SplinteredSane bmicanecked from the ceiling A sea of shatlered gluse spreadar Slbe trac ashing in Uhe hysterical strobe of red emeryemcy lights ikeseis dco ball We were boxed in a wall hard to one side and paserz te osher two sre from a ereature whose only natural instance wasizecuble mead ye it made no move to chine the gup It seemed rooted toesron sheds ikea drunk ara seepwalker deaths liad drooplagmins nes of snakes T charmed to sleepBE\n",
      "-------------------------------------------\n",
      "Library of Souls\n",
      "-------------------------------------------\n",
      "ss Hollows are bom lusting uller the souls of peculiars and here weSearapal fore ike abut bitesized Addin bravely standing his groundEZ Es failat teution Emma moored against me for support till tos daredReticle to make more than a match flame our hac ladder againat theLuks PeucboothHeyond oar grim cree the undergrvund station lke lkete attennarh ua nighielub bombingSean from burst pipes shricked forth in ghostly curtains Splintered monitorsSine bmacaneched frum the ceiling A sca of shallered plana spread all theazn ih tacks ashing in the hysterical strobe of red emergency lighis like anse Zis deo ball We were boxed in a wall hard to one side and past shinhz eke to sre from wereature whose only malural instinct vas toizvenle aad yet t made no muve to clove the pup It eeemnod rooted totheersonishecs ikea drunk ora seepwalker deaths lead drooping tswes  esl of snakes Td charmed lo sleep\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9MiqbxP8tymT",
    "outputId": "6e6a35d6-6dcc-4a36-c603-f01872c93e6e"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "from spellchecker import SpellChecker\n",
    "spell = SpellChecker()\n",
    "for key in d.keys():\n",
    "    word_list = d[key].split()\n",
    "    corrected_words = []\n",
    "    for word in word_list:\n",
    "        corrected_words.append(spell.correction(word))\n",
    "    print(corrected_words)\n",
    "    print('----------------------------------------')\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['Library', 'of', 'Souls', 'TIE', 'MONSTER', 'STOOD', 'toi', 'tongues', 'length', 'away', 'eyes', 'find', 'on', 'asshats', 'sired', 'bran', 'crowded', 'with', 'fantasies', 'of', 'murder', 'Its', 'hunger', 'forthwith', 'at', 'Hollows', 'are', 'bom', 'lusting', 'for', 'the', 'souls', 'of', 'peculiars', 'ated', 'hereezvarapel', 'before', 'ke', 'buf', 'itemized', 'addison', 'bravely', 'standing', 'is', 'Go', 'till', 'attention', 'mma', 'moored', 'against', 'me', 'for', 'support', 'al', 'torte', 'epoch', 'to', 'make', 'more', 'than', 'a', 'match', 'flame', 'our', 'hacks', 'adder', 'gaintsci', 'pros', 'boathHeyoud', 'oar', 'grim', 'ci', 'the', 'underground', 'station', 'ledkedYeofimanath', 'ua', 'nightclub', 'bombings', 'from', 'burn', 'pipes', 'shrieked', 'forth', 'in', 'ghostly', 'curtains', 'SplinteredSane', 'bmicanecked', 'from', 'the', 'ceiling', 'A', 'sea', 'of', 'shattered', 'glue', 'spreader', 'sloe', 'trac', 'ashing', 'in', 'the', 'hysterical', 'strobe', 'of', 'red', 'emergency', 'lights', 'ikeseis', 'dco', 'ball', 'We', 'were', 'boxed', 'in', 'a', 'wall', 'hard', 'to', 'one', 'side', 'and', 'paper', 'te', 'other', 'two', 'sre', 'from', 'a', 'creature', 'whose', 'only', 'natural', 'instance', 'wasizecuble', 'mead', 'ye', 'it', 'made', 'no', 'move', 'to', 'chine', 'the', 'gup', 'It', 'seemed', 'rooted', 'torsion', 'sheds', 'ikea', 'drunk', 'ara', 'sleepwalker', 'deaths', 'lead', 'drooplagmins', 'nes', 'of', 'snakes', 'i', 'charmed', 'to', 'sleepe']\n",
      "----------------------------------------\n",
      "['Library', 'of', 'Souls']\n",
      "----------------------------------------\n",
      "['is', 'Hollows', 'are', 'bom', 'lusting', 'ulcer', 'the', 'souls', 'of', 'peculiars', 'and', 'here', 'weSearapal', 'fore', 'ike', 'abut', 'itemized', 'adding', 'bravely', 'standing', 'his', 'grounded', 'Es', 'failed', 'mention', 'Emma', 'moored', 'against', 'me', 'for', 'support', 'till', 'tos', 'daredReticle', 'to', 'make', 'more', 'than', 'a', 'match', 'flame', 'our', 'hac', 'ladder', 'against', 'whelks', 'PeucboothHeyond', 'oar', 'grim', 'cree', 'the', 'underground', 'station', 'lke', 'let', 'attennarh', 'ua', 'nightclub', 'bombingSean', 'from', 'burst', 'pipes', 'shrieked', 'forth', 'in', 'ghostly', 'curtains', 'Splintered', 'monitorsSine', 'bmacaneched', 'frum', 'the', 'ceiling', 'A', 'sca', 'of', 'shattered', 'plan', 'spread', 'all', 'then', 'ih', 'tacks', 'ashing', 'in', 'the', 'hysterical', 'strobe', 'of', 'red', 'emergency', 'lights', 'like', 'anse', 'Zis', 'deo', 'ball', 'We', 'were', 'boxed', 'in', 'a', 'wall', 'hard', 'to', 'one', 'side', 'and', 'past', 'shine', 'eke', 'to', 'sre', 'from', 'creature', 'whose', 'only', 'natural', 'instinct', 'vas', 'toizvenle', 'and', 'yet', 'i', 'made', 'no', 'move', 'to', 'clove', 'the', 'pup', 'It', 'eeemnod', 'rooted', 'totheersonishecs', 'ikea', 'drunk', 'ora', 'sleepwalker', 'deaths', 'lead', 'drooping', 'times', 'esl', 'of', 'snakes', 'to', 'charmed', 'lo', 'sleep']\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "cv2.imwrite('Copy.jpg', im2)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "pdf = FPDF()\n",
    "pdf.add_page()\n",
    "pdf.set_font('Arial',size=15)\n",
    "for k in d.keys():\n",
    "    text = d[k]\n",
    "    while len(text) > 50:\n",
    "        line = text[:50]\n",
    "        text = text[50:]\n",
    "        if text[0] != ' ':\n",
    "            index = text.find(' ')\n",
    "            if index == -1:\n",
    "                line += text\n",
    "                text = ''\n",
    "            else:\n",
    "                line += text[:index]\n",
    "                text = text[index:]\n",
    "        pdf.cell(200, 10, txt = line, ln=1, align = 'C')        \n",
    "    pdf.cell(200, 10, txt = text[:], ln=1, align = 'C')\n",
    "pdf.output(\"Final.pdf\")"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "colab": {
   "name": "TextDetection.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}